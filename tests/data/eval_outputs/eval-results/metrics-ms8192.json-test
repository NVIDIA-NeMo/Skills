{
  "answer-judge": {
    "pass@1": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 43.64583333333333,
        "std": 4.726688043557678
      },
      "false_positives": {
        "avg": 17.916666666666668,
        "std": 6.052432935972479
      },
      "false_negatives": {
        "avg": 22.916666666666668,
        "std": 9.816015824491455
      },
      "invalid_judgements": {
        "avg": 11.666666666666668,
        "std": 8.897565210026093
      },
      "precision": {
        "avg": 61.17857142857142,
        "std": 9.780607809111162
      },
      "recall": {
        "avg": 47.14285714285714,
        "std": 9.147320339189783
      },
      "f1": {
        "avg": 52.77472527472527,
        "std": 8.008068270008657
      }
    },
    "pass@2": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 53.333333333333336,
        "std": 5.579808174055741
      },
      "false_positives": {
        "avg": 15.0,
        "std": 5.65194165260439
      },
      "false_negatives": {
        "avg": 25.416666666666668,
        "std": 5.574620066774855
      },
      "invalid_judgements": {
        "avg": 4.166666666666667,
        "std": 5.5901699437494745
      },
      "precision": {
        "avg": 68.13095238095238,
        "std": 8.439888487834116
      },
      "recall": {
        "avg": 52.857142857142854,
        "std": 6.54653670707977
      },
      "f1": {
        "avg": 59.15251415251415,
        "std": 5.829437147260951
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 45.0,
        "std": 5.527707983925667
      },
      "false_positives": {
        "avg": 19.166666666666664,
        "std": 3.584302194601094
      },
      "false_negatives": {
        "avg": 22.708333333333336,
        "std": 5.183273043593637
      },
      "invalid_judgements": {
        "avg": 13.125,
        "std": 5.315562842572113
      },
      "precision": {
        "avg": 58.583333333333336,
        "std": 5.953083291897745
      },
      "recall": {
        "avg": 45.71428571428571,
        "std": 7.626484465736652
      },
      "f1": {
        "avg": 50.90617715617715,
        "std": 6.243427827415622
      }
    },
    "pass@3": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 58.541666666666664,
        "std": 5.468501978502785
      },
      "false_positives": {
        "avg": 13.333333333333334,
        "std": 4.85912657903775
      },
      "false_negatives": {
        "avg": 24.583333333333336,
        "std": 3.200477394945253
      },
      "invalid_judgements": {
        "avg": 1.6666666666666667,
        "std": 3.3333333333333335
      },
      "precision": {
        "avg": 71.52380952380952,
        "std": 8.086269541762807
      },
      "recall": {
        "avg": 55.71428571428571,
        "std": 4.285714285714286
      },
      "f1": {
        "avg": 62.47252747252746,
        "std": 5.024093622240053
      }
    },
    "pass@1[avg-of-3]": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 44.30555555555556,
        "std": 4.849191736137804
      },
      "false_positives": {
        "avg": 19.583333333333332,
        "std": 3.2244963239566387
      },
      "false_negatives": {
        "avg": 22.77777777777778,
        "std": 4.77906959280146
      },
      "invalid_judgements": {
        "avg": 13.333333333333332,
        "std": 5.0154083570188295
      },
      "precision": {
        "avg": 57.45238095238095,
        "std": 5.9044578774777055
      },
      "recall": {
        "avg": 44.76190476190476,
        "std": 5.512303287042963
      },
      "f1": {
        "avg": 49.920912420912416,
        "std": 5.083170633442309
      }
    },
    "pass@4": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 61.25,
        "std": 5.448623679425843
      },
      "false_positives": {
        "avg": 12.500000000000002,
        "std": 4.930066485916347
      },
      "false_negatives": {
        "avg": 25.833333333333332,
        "std": 2.5000000000000004
      },
      "invalid_judgements": {
        "avg": 0.4166666666666667,
        "std": 1.8162078931419474
      },
      "precision": {
        "avg": 72.94047619047619,
        "std": 7.730316603126973
      },
      "recall": {
        "avg": 55.71428571428571,
        "std": 4.285714285714286
      },
      "f1": {
        "avg": 62.95621045621046,
        "std": 4.605128760281228
      }
    },
    "pass@1[avg-of-4]": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 43.64583333333333,
        "std": 4.726688043557678
      },
      "false_positives": {
        "avg": 19.583333333333336,
        "std": 3.3850160019316498
      },
      "false_negatives": {
        "avg": 23.333333333333336,
        "std": 4.093100563414271
      },
      "invalid_judgements": {
        "avg": 13.4375,
        "std": 3.923918375382784
      },
      "precision": {
        "avg": 56.92261904761905,
        "std": 6.114491888490961
      },
      "recall": {
        "avg": 43.74999999999999,
        "std": 5.518406121558016
      },
      "f1": {
        "avg": 49.04353979353979,
        "std": 5.1939429705789495
      }
    },
    "majority@2": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 47.916666666666664,
        "std": 6.249999999999999
      },
      "false_positives": {
        "avg": 15.0,
        "std": 5.65194165260439
      },
      "false_negatives": {
        "avg": 29.583333333333332,
        "std": 7.671646933134154
      },
      "invalid_judgements": {
        "avg": 4.166666666666667,
        "std": 5.5901699437494745
      },
      "precision": {
        "avg": 64.69047619047619,
        "std": 8.60018324964286
      },
      "recall": {
        "avg": 45.71428571428571,
        "std": 9.689042833036098
      },
      "f1": {
        "avg": 52.917748917748916,
        "std": 8.131403090833112
      }
    },
    "majority@3": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 47.91666666666667,
        "std": 7.739239842086129
      },
      "false_positives": {
        "avg": 21.666666666666668,
        "std": 4.85912657903775
      },
      "false_negatives": {
        "avg": 29.166666666666668,
        "std": 6.180165405913053
      },
      "invalid_judgements": {
        "avg": 1.6666666666666667,
        "std": 3.3333333333333335
      },
      "precision": {
        "avg": 56.28571428571428,
        "std": 7.746844870150483
      },
      "recall": {
        "avg": 47.857142857142854,
        "std": 9.340497736158586
      },
      "f1": {
        "avg": 51.46520146520146,
        "std": 8.058399930712296
      }
    },
    "majority@4": {
      "num_entries": 12,
      "avg_tokens": {
        "avg": 191.1,
        "std": 28.028378476108816
      },
      "correct_judgements": {
        "avg": 48.33333333333333,
        "std": 8.164965809277259
      },
      "false_positives": {
        "avg": 17.916666666666668,
        "std": 6.601241465731191
      },
      "false_negatives": {
        "avg": 31.666666666666668,
        "std": 6.2360956446232345
      },
      "invalid_judgements": {
        "avg": 0.4166666666666667,
        "std": 1.8162078931419474
      },
      "precision": {
        "avg": 60.357142857142854,
        "std": 10.42180145551772
      },
      "recall": {
        "avg": 45.71428571428571,
        "std": 10.690449676496975
      },
      "f1": {
        "avg": 51.446886446886445,
        "std": 9.730116135218033
      }
    }
  },
  "arena-hard": {
    "pass@1": {
      "num_entries": 10,
      "score": 21.28,
      "95_CI": [
        -10.64,
        8.51
      ],
      "invalid_scores": 3,
      "avg_tokens": 98
    }
  },
  "gpqa": {
    "pass@1": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 38.75,
        "std": 5.0775240028974755
      },
      "no_answer": {
        "avg": 27.5,
        "std": 20.766559657295186
      }
    },
    "pass@2": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 45.625,
        "std": 4.463392767839281
      },
      "no_answer": {
        "avg": 21.25,
        "std": 19.803724397193573
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 37.5,
        "std": 9.682458365518542
      },
      "no_answer": {
        "avg": 30.625,
        "std": 16.044372066241795
      }
    },
    "pass@3": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 48.75,
        "std": 2.5
      },
      "no_answer": {
        "avg": 15.0,
        "std": 16.583123951777
      }
    },
    "pass@1[avg-of-3]": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 39.166666666666664,
        "std": 7.021791477646966
      },
      "no_answer": {
        "avg": 30.0,
        "std": 11.902380714238085
      }
    },
    "pass@4": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": 50.0,
      "no_answer": {
        "avg": 11.25,
        "std": 12.43734296383275
      }
    },
    "pass@1[avg-of-4]": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 38.75,
        "std": 5.0775240028974755
      },
      "no_answer": {
        "avg": 30.3125,
        "std": 10.13097817340458
      }
    },
    "majority@2": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 42.5,
        "std": 11.4564392373896
      },
      "no_answer": {
        "avg": 21.25,
        "std": 19.803724397193573
      }
    },
    "majority@3": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": {
        "avg": 47.5,
        "std": 7.5
      },
      "no_answer": {
        "avg": 15.0,
        "std": 16.583123951777
      }
    },
    "majority@4": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 5220.7,
        "std": 704.5688823670828
      },
      "symbolic_correct": 50.0,
      "no_answer": {
        "avg": 11.25,
        "std": 12.43734296383275
      }
    }
  },
  "human-eval": {
    "pass@1": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 1700.8,
        "std": 658.3741033789224
      },
      "passing_base_tests": 75.0,
      "passing_plus_tests": {
        "avg": 63.75,
        "std": 8.75
      }
    },
    "pass@2": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 1700.8,
        "std": 658.3741033789224
      },
      "passing_base_tests": 75.0,
      "passing_plus_tests": {
        "avg": 70.0,
        "std": 10.0
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 4,
      "avg_tokens": {
        "avg": 1700.8,
        "std": 658.3741033789224
      },
      "passing_base_tests": 75.0,
      "passing_plus_tests": {
        "avg": 63.75,
        "std": 8.75
      }
    }
  },
  "ifeval": {
    "pass@1": {
      "num_prompts": 3,
      "num_instructions": 5,
      "average_score": 46.666666666666664,
      "prompt_strict_accuracy": 33.33333333333333,
      "instruction_strict_accuracy": 60.0,
      "prompt_loose_accuracy": 33.33333333333333,
      "instruction_loose_accuracy": 60.0,
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2562.15,
        "std": 185.82095549210806
      }
    },
    "pass@2": {
      "num_prompts": 3,
      "num_instructions": 5,
      "average_score": 46.666666666666664,
      "prompt_strict_accuracy": 33.33333333333333,
      "instruction_strict_accuracy": 60.0,
      "prompt_loose_accuracy": 33.33333333333333,
      "instruction_loose_accuracy": 60.0,
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2562.15,
        "std": 185.82095549210806
      }
    },
    "pass@1[avg-of-2]": {
      "num_prompts": 3,
      "num_instructions": 5,
      "average_score": 46.666666666666664,
      "prompt_strict_accuracy": 33.33333333333333,
      "instruction_strict_accuracy": 60.0,
      "prompt_loose_accuracy": 33.33333333333333,
      "instruction_loose_accuracy": 60.0,
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2562.15,
        "std": 185.82095549210806
      }
    },
    "pass@3": {
      "num_prompts": 3,
      "num_instructions": 5,
      "average_score": 46.666666666666664,
      "prompt_strict_accuracy": 33.33333333333333,
      "instruction_strict_accuracy": 60.0,
      "prompt_loose_accuracy": 33.33333333333333,
      "instruction_loose_accuracy": 60.0,
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2562.15,
        "std": 185.82095549210806
      }
    },
    "pass@1[avg-of-3]": {
      "num_prompts": 3,
      "num_instructions": 5,
      "average_score": 46.666666666666664,
      "prompt_strict_accuracy": 33.33333333333333,
      "instruction_strict_accuracy": 60.0,
      "prompt_loose_accuracy": 33.33333333333333,
      "instruction_loose_accuracy": 60.0,
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2562.15,
        "std": 185.82095549210806
      }
    }
  },
  "math": {
    "pass@1": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 43.095238095238095,
        "std": 5.923740621249872
      },
      "no_answer": {
        "avg": 54.28571428571429,
        "std": 5.714285714285717
      }
    },
    "pass@2": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 49.04761904761905,
        "std": 7.2374686445574605
      },
      "no_answer": {
        "avg": 49.285714285714285,
        "std": 7.107053122190146
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 43.21428571428571,
        "std": 6.952829404975637
      },
      "no_answer": {
        "avg": 52.5,
        "std": 4.6702488680792955
      }
    },
    "pass@3": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 52.142857142857146,
        "std": 8.175373673042571
      },
      "no_answer": {
        "avg": 47.142857142857146,
        "std": 6.546536707079775
      }
    },
    "pass@1[avg-of-3]": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 43.09523809523809,
        "std": 5.923740621249868
      },
      "no_answer": {
        "avg": 52.38095238095237,
        "std": 3.6885555678165907
      }
    },
    "majority@2": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 46.42857142857143,
        "std": 8.89278542713481
      },
      "no_answer": {
        "avg": 49.285714285714285,
        "std": 7.107053122190146
      }
    },
    "majority@3": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 48.57142857142857,
        "std": 9.47607082958686
      },
      "no_answer": {
        "avg": 47.142857142857146,
        "std": 6.546536707079775
      }
    },
    "rm_best@1": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 39.285714285714285,
        "std": 8.892785427134807
      },
      "no_answer": {
        "avg": 54.28571428571429,
        "std": 5.714285714285717
      }
    },
    "rm_majority@1": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 39.285714285714285,
        "std": 8.892785427134807
      },
      "no_answer": {
        "avg": 54.28571428571429,
        "std": 5.714285714285717
      }
    },
    "rm_best@2": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 43.57142857142857,
        "std": 9.55649154304261
      },
      "no_answer": {
        "avg": 49.285714285714285,
        "std": 7.107053122190146
      }
    },
    "rm_majority@2": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 43.57142857142857,
        "std": 9.55649154304261
      },
      "no_answer": {
        "avg": 49.285714285714285,
        "std": 7.107053122190146
      }
    },
    "rm_best@3": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 44.285714285714285,
        "std": 8.921425711997712
      },
      "no_answer": {
        "avg": 47.142857142857146,
        "std": 6.546536707079775
      }
    },
    "rm_majority@3": {
      "num_entries": 7,
      "avg_tokens": {
        "avg": 9575.85,
        "std": 252.86404944159224
      },
      "gen_seconds": {
        "avg": 1183208347.75,
        "std": 683097924.0113959
      },
      "symbolic_correct": {
        "avg": 48.57142857142857,
        "std": 9.47607082958686
      },
      "no_answer": {
        "avg": 47.142857142857146,
        "std": 6.546536707079775
      }
    }
  },
  "math-aime25": {
    "pass@1": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 46.66666666666667,
        "std": 5.163977794943223
      },
      "no_answer": {
        "avg": 56.0,
        "std": 8.0
      }
    },
    "pass@2": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 51.333333333333336,
        "std": 7.916228058025278
      },
      "no_answer": {
        "avg": 49.0,
        "std": 9.9498743710662
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 46.5,
        "std": 6.5383484153110105
      },
      "no_answer": {
        "avg": 53.5,
        "std": 6.5383484153110105
      }
    },
    "pass@3": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 54.0,
        "std": 9.16515138991168
      },
      "no_answer": {
        "avg": 46.0,
        "std": 9.16515138991168
      }
    },
    "pass@1[avg-of-3]": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 46.666666666666664,
        "std": 5.163977794943221
      },
      "no_answer": {
        "avg": 53.33333333333333,
        "std": 5.163977794943223
      }
    },
    "majority@2": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 51.0,
        "std": 9.9498743710662
      },
      "no_answer": {
        "avg": 49.0,
        "std": 9.9498743710662
      }
    },
    "majority@3": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 54.0,
        "std": 9.16515138991168
      },
      "no_answer": {
        "avg": 46.0,
        "std": 9.16515138991168
      }
    },
    "rm_best@1": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 44.0,
        "std": 8.0
      },
      "no_answer": {
        "avg": 56.0,
        "std": 8.0
      }
    },
    "rm_majority@1": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 44.0,
        "std": 8.0
      },
      "no_answer": {
        "avg": 56.0,
        "std": 8.0
      }
    },
    "rm_best@2": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 51.0,
        "std": 9.9498743710662
      },
      "no_answer": {
        "avg": 49.0,
        "std": 9.9498743710662
      }
    },
    "rm_majority@2": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 51.0,
        "std": 9.9498743710662
      },
      "no_answer": {
        "avg": 49.0,
        "std": 9.9498743710662
      }
    },
    "rm_best@3": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 54.0,
        "std": 9.16515138991168
      },
      "no_answer": {
        "avg": 46.0,
        "std": 9.16515138991168
      }
    },
    "rm_majority@3": {
      "num_entries": 5,
      "avg_tokens": {
        "avg": 9927.85,
        "std": 293.6629488035561
      },
      "gen_seconds": {
        "avg": 42037.0,
        "std": 27495.45416973504
      },
      "symbolic_correct": {
        "avg": 54.0,
        "std": 9.16515138991168
      },
      "no_answer": {
        "avg": 46.0,
        "std": 9.16515138991168
      }
    }
  },
  "math-aime24": {
    "pass@1": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 34.16666666666667,
        "std": 15.343293866268308
      },
      "no_answer": 50.0
    },
    "pass@2": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 43.33333333333333,
        "std": 12.247448713915889
      },
      "no_answer": 50.0
    },
    "pass@1[avg-of-2]": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 35.0,
        "std": 16.583123951777
      },
      "no_answer": 50.0
    },
    "pass@3": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 47.5,
        "std": 10.897247358851684
      },
      "no_answer": 50.0
    },
    "pass@1[avg-of-3]": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 34.166666666666664,
        "std": 15.343293866268308
      },
      "no_answer": 50.0
    },
    "majority@2": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 35.0,
        "std": 16.583123951777
      },
      "no_answer": 50.0
    },
    "majority@3": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 35.0,
        "std": 22.9128784747792
      },
      "no_answer": 50.0
    },
    "rm_best@1": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 27.5,
        "std": 24.8746859276655
      },
      "no_answer": 50.0
    },
    "rm_majority@1": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 27.5,
        "std": 24.8746859276655
      },
      "no_answer": 50.0
    },
    "rm_best@2": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 25.0,
        "std": 25.0
      },
      "no_answer": 50.0
    },
    "rm_majority@2": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 25.0,
        "std": 25.0
      },
      "no_answer": 50.0
    },
    "rm_best@3": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 20.0,
        "std": 24.49489742783178
      },
      "no_answer": 50.0
    },
    "rm_majority@3": {
      "num_entries": 2,
      "avg_tokens": {
        "avg": 8696.15,
        "std": 445.59166004313863
      },
      "gen_seconds": {
        "avg": 1183196347.75,
        "std": 683118708.5156846
      },
      "symbolic_correct": {
        "avg": 35.0,
        "std": 22.9128784747792
      },
      "no_answer": 50.0
    }
  },
  "minif2f": {
    "pass@1": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 30.833333333333332,
        "std": 11.81453906563152
      },
      "timeout_error": {
        "avg": 65.0,
        "std": 32.44653722321964
      }
    },
    "pass@2": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 51.66666666666667,
        "std": 16.583123951777
      },
      "timeout_error": {
        "avg": 50.0,
        "std": 28.867513459481287
      }
    },
    "pass@1[avg-of-2]": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 30.833333333333336,
        "std": 22.530843057659624
      },
      "timeout_error": {
        "avg": 69.16666666666666,
        "std": 22.530843057659624
      }
    },
    "pass@3": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 65.41666666666666,
        "std": 18.498310733685926
      },
      "timeout_error": {
        "avg": 40.0,
        "std": 29.05932629027116
      }
    },
    "pass@1[avg-of-3]": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 30.555555555555554,
        "std": 16.43355495305449
      },
      "timeout_error": {
        "avg": 69.44444444444444,
        "std": 16.433554953054486
      }
    },
    "pass@4": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 75.0,
        "std": 20.749832663314553
      },
      "timeout_error": {
        "avg": 25.000000000000004,
        "std": 20.749832663314557
      }
    },
    "pass@1[avg-of-4]": {
      "num_entries": 3,
      "avg_tokens": {
        "avg": 2519.1,
        "std": 256.95464580349585
      },
      "lean4_correct": {
        "avg": 30.833333333333332,
        "std": 11.81453906563152
      },
      "timeout_error": {
        "avg": 69.16666666666666,
        "std": 11.81453906563152
      }
    }
  }
}
