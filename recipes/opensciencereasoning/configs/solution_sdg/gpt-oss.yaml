cluster: local
base_output_dir: ""
expname: ""
suffix: ""  # Suffix for experiment names
dataset_name: ""  # Optional dataset name for id generation
is_mcq: False



# Input file for the first stage (generate_solutions)
# It must include the field "problem"
# All the data in this file will be processed with the same prompt
# Make sure the problems fit the prompt you are using
input_file: "/workspace/test_data.json"

# Can define initial dependency for the `generate_solutions` stage to run after
initial_dependency: ""

# Define the full sequence of stages for this mode
pipeline_stages:
  - filter_problems          # Filter problems based on format

# Directory structure configuration
directories:
  step-0-filter-problems: ${base_output_dir}/solution-sdg/step-0-filter-problems
  step-2.2-difficulty-estimation: ${base_output_dir}/solution-sdg/step-2.2-difficulty-estimation
  
# Stage-specific configurations
stages:
  filter_problems:
    output_dir: ${directories.step-0-filter-problems}
    input_file: ${input_file}
    dataset_name: ${dataset_name}
    is_mcq: ${is_mcq}
    remove_images: True
    num_options: None
    option_format_regex: None
    deduplicate: True
  
  difficulty_estimation:
    output_dir: ${directories.step-2.2-difficulty-estimation}
    input_file: ${directories.step-0-filter-problems}/final_result.jsonl 
    dependencies:
      - filter_problems
    is_mcq: ${is_mcq}
    mcq_prompt_config: ""
    openq_prompt_config: ""

    generation_kwargs:
      model: /hf_models/Qwen3-30B-A3B
      server_type: vllm
      server_gpus: 8
      server_nodes: 2
      server_args: "++inference.tokens_to_generate=16000"
      num_random_seeds: 5
      num_chunks: 10  
    
    judge_kwargs:
      model: /hf_models/Qwen2.5-32B-Instruct
      server_type: trtllm
      server_gpus: 8
      server_nodes: 2
      server_args: "++skip_filled=True  ++prompt_config=judge/general-judge "
      num_random_seeds: 1
      num_chunks: 10
      

    



